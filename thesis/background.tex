This chapter elaborates on relevant concepts revolving around energy-aware
resource management in edge and fog computing. Section
\ref{sec:edge_and_fog_computing_paradigms} introduces the motivation and
explains the necessity for edge and fog computing paradigms. Section
\ref{sec:testbeds_emulations_and_simulations}
focuses on the development process of edge and fog infrastructure and outlines
the essential use of testbeds, simulations and emulations. Section
\ref{sec:energy_proportional_computing} presents main concepts of energy
proportional computing. Since the renewable energy source of the hardware
testbed is not able to supply uninterrupted power, section
\ref{sec:energy-aware_resource_management} outlines specific techniques used in
energy-aware resource management. Dynamic voltage and frequency scaling will be
the primary technique used in the hardware testbed and is therefore elaborated
on further in section \ref{sec:dynamic_voltage_and_frequency_scaling}.

\section{Edge and Fog Computing Paradigms}
\label{sec:edge_and_fog_computing_paradigms}

In 2012 Xia et al. defines the Internet of Things as the networked
interconnection of everyday objects, which are often equipped with ubiquitous
intelligence \cite{xia2012}. Since then, IoT devices have spread to all aspects
of our everyday lives. Cisco estimates that by 2023 there will be 14.7 billion
machine-to-machine connections, more than a 140\% increase to 2018
\cite{cisco2020}. The rise of IoT results in a significant increase of devices
connected to the internet and may, with its current rate of development, soon
grow to a point, that our current network structure cannot manage. In specific,
major challenges that are posed by traditional cloud-centric IoT architectures
include the excess of bandwidth availability due to the increasingly large and
high-frequent rate of data being produced by IoT devices, and high end-to-end
latency along with unstable, intermittent network connectivity due to
potentially large physical distance \cite{buyya2019}.

As an alternative to cloud-centric architectures, computing resources can be
brought closer to end-devices. Using these resources, even partially, for data
processing would reduce the amount of data sent to the cloud. With the physical
proximity of provided services, latency for end-devices is highly lowered, cloud
servers are relieved due to less network traffic and network throughput is
consequently raised, favoring both end-devices and cloud servers. With these
alternative paradigms, fog and edge computing are introduced.

The terms \emph{fog} and \emph{edge} computing are often used inconsistently
throughout current literature. The research field is still rather young and
allows for multiple interpretations. In the context of this thesis, the
distinction from Iorga et al., from the National Institute of Standards and
Technology, will be used. Iorga et al.\ define fog computing as a layered model
for enabling ubiquitous access to a shared continuum of scalable computing
resource, whereas edge computing describes the layer of end-devices that are
used to do limited local computing or sensor metering \cite{iorga2018}. A
concurrent example for this interpretation of the terminology is presented by
Atos' BullSequana edge computing servers, utilized for visual quality control in
production lines. Possible defects are detected locally and may subsequently be
transmitted to a nearby fog server for further processing \cite{atos2019,
atos2020}.

\section{Testbeds, Emulations and Simulations in Edge and Fog Computing Environments}
\label{sec:testbeds_emulations_and_simulations}

Opposed to simulators or emulators, hardware testbeds are subject to real-life
environments and therefore able to accommodate more realistic experiments. While
some elaborate approaches are already in use, none of these are deployed on a
large scale yet and are therefore, for the most part, unfit for research
revolving around fog and edge computing. Deploying a large scale physical
testbed for research or commercial purposes is not only very cost intensive, but
also highly time consuming.

Emulators serve as a more abstract alternative. Instead of physically setting up
and initializing hardware and network for the desired system, the components are
imitated on a computer, while keeping all functionality of the emulated system.
This enables multiple components to be emulated on a single system, making them
independent from their physical location. While experiments utilizing emulators
are saving space and costs to a certain extent, execution time is bound by the
emulated hardware, making them very inefficient for many scenarios, where
gathering data takes a lot of time.

Simulators on the other hand
\cite{svorobej2019}
%Thus, simulating or emulating environments for fog
%and edge computing paradigms seems to be most opportune for development and
%research processes.

\section{Energy Proportional Computing}
\label{sec:energy_proportional_computing}

\section{Dynamic Resource Management}
\label{sec:dynamic_resource_management}

\subsection{Energy-Aware Resource Management}
\label{sec:energy-aware_resource_management}

\subsection{Dynamic Voltage and Frequency Scaling}
\label{sec:dynamic_voltage_and_frequency_scaling}
